{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_oKmPYp9jY7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## import packages required for this project\n",
    "import pandas as pd\n",
    "import html\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Embedding, LSTM, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "6K9FSgKk9lmC",
    "outputId": "4ae64399-bcb8-401f-fc4c-bd85b9fa1ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M0PDuNgu9jY-"
   },
   "outputs": [],
   "source": [
    "## read SMS Spam dataset from UCI ML repository https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "#sms = pd.read_csv(\"/content/gdrive/My Drive/spam.csv\", encoding = \"latin-1\")\n",
    "sms = pd.read_csv(\"spam.csv\", encoding = \"latin-1\")\n",
    "\n",
    "## data cleaning\n",
    "## convert html entities to regular characters. e.g. &amp; &lt; &gt; etc.\n",
    "for index, msg in sms.v2.iteritems():\n",
    "    sms.v2[index] = html.unescape(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-U-IcKM89jZC"
   },
   "outputs": [],
   "source": [
    "## Recurrent Neural Network LSTM\n",
    "spam = sms.loc[sms[\"v1\"] == \"spam\"]\n",
    "ham = sms.loc[sms[\"v1\"] == \"ham\"]\n",
    "spam = spam.v2.tolist()\n",
    "ham = ham.v2.tolist()\n",
    "x = np.asarray(spam + ham)\n",
    "y = np.concatenate((np.ones(len(spam)), np.zeros(len(ham))))\n",
    "tokenizer = Tokenizer(num_words = 3800)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "x = sequence.pad_sequences(x, maxlen = 380)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 4450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "1EmHmgeo9jZF",
    "outputId": "693418dd-5403-4c77-e5aa-019546fd3da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 146,497\n",
      "Trainable params: 146,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_text_rnn = Sequential()\n",
    "model_text_rnn.add(Embedding(input_dim = 3800, output_dim = 32, input_length = 380))\n",
    "model_text_rnn.add(Dropout(0.2))\n",
    "model_text_rnn.add(LSTM(64))\n",
    "model_text_rnn.add(Dense(1, activation = \"sigmoid\"))\n",
    "model_text_rnn.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_text_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "e3k1o24M9jZK",
    "outputId": "99542585-5d6b-4a7d-b652-d97b41c2bc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2786 samples, validate on 2786 samples\n",
      "Epoch 1/10\n",
      "2786/2786 [==============================] - 33s 12ms/step - loss: 0.5800 - acc: 0.8349 - val_loss: 0.3450 - val_acc: 0.8715\n",
      "Epoch 2/10\n",
      "2786/2786 [==============================] - 30s 11ms/step - loss: 0.3139 - acc: 0.8604 - val_loss: 0.2283 - val_acc: 0.8981\n",
      "Epoch 3/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.1549 - acc: 0.9472 - val_loss: 0.1105 - val_acc: 0.9806\n",
      "Epoch 4/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0811 - acc: 0.9810 - val_loss: 0.0796 - val_acc: 0.9803\n",
      "Epoch 5/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0479 - acc: 0.9882 - val_loss: 0.0624 - val_acc: 0.9849\n",
      "Epoch 6/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0286 - acc: 0.9943 - val_loss: 0.0634 - val_acc: 0.9838\n",
      "Epoch 7/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0175 - acc: 0.9957 - val_loss: 0.0526 - val_acc: 0.9849\n",
      "Epoch 8/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0273 - acc: 0.9943 - val_loss: 0.0661 - val_acc: 0.9795\n",
      "Epoch 9/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0221 - acc: 0.9953 - val_loss: 0.0553 - val_acc: 0.9849\n",
      "Epoch 10/10\n",
      "2786/2786 [==============================] - 31s 11ms/step - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0552 - val_acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50b1f06e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_text_rnn.fit(x_train, y_train, epochs = 10, batch_size = 128, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0BVn-owN9jZN"
   },
   "outputs": [],
   "source": [
    "## Naive Bayes Classifier\n",
    "sms[\"v1\"] = sms[\"v1\"].map({\"spam\":1, \"ham\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqczfw0e9jZP",
    "outputId": "ea195152-7483-444c-9577-e14760c5877d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9201435621354868"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(sms[\"v2\"], sms[\"v1\"], test_size = 0.8, random_state = 4421)\n",
    "x_train = count_vector.fit_transform(x_train)\n",
    "x_test = count_vector.transform(x_test)\n",
    "naive_bayes = GaussianNB()\n",
    "model_nb = naive_bayes.fit(x_train.toarray(), y_train)\n",
    "pred = model_nb.predict(x_test.toarray())\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-EAtoZHf9jZT"
   },
   "outputs": [],
   "source": [
    "## my own tokenizer\n",
    "pattern_punctuation = r'''(?x)\n",
    "[\\/#!$%\\^&\\*;:{}=\\_`~()] # basically all punctuations except , . -\n",
    "'''\n",
    "sms[\"puncPerSent\"] = sms[\"v2\"].apply(lambda x: len(nltk.regexp_tokenize(x, pattern_punctuation))/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3GP3eX0O9jZW"
   },
   "outputs": [],
   "source": [
    "def longCapital(s):\n",
    "    list_of_uppercase_runs = re.findall(r\"[A-Z0-9]+\", s)\n",
    "\n",
    "    # find out what the longest string is in your list\n",
    "    try:\n",
    "        longest_string = max(list_of_uppercase_runs, key = len)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    # return the length of this string to the user\n",
    "    return len(longest_string)\n",
    "sms[\"longCapital\"] = sms[\"v2\"].apply(longCapital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tBFKAYS39jZZ"
   },
   "outputs": [],
   "source": [
    "def numbers(s):\n",
    "    list_of_numbers = re.findall(r\"[0-9]\", s)\n",
    "    if list_of_numbers == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(list_of_numbers)\n",
    "sms[\"numbers\"] = sms[\"v2\"].apply(lambda x: numbers(x)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qwFfAMI89jZb"
   },
   "outputs": [],
   "source": [
    "sms[\"length\"] = sms[\"v2\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EUrisClH9jZd"
   },
   "outputs": [],
   "source": [
    "def refind(string, text):\n",
    "    myregex = re.escape(string)\n",
    "    l = re.findall(myregex, text)\n",
    "    if l == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(l)\n",
    "sms[\"v2\"] = sms[\"v2\"].apply(lambda x: x.lower())\n",
    "sms[\"txt\"] = sms[\"v2\"].apply(lambda x: refind(\"txt\", x))\n",
    "sms[\"http\"] = sms[\"v2\"].apply(lambda x: refind(\"http\", x))\n",
    "sms[\"credit\"] = sms[\"v2\"].apply(lambda x: refind(\"credit\", x))\n",
    "sms[\"congrat\"] = sms[\"v2\"].apply(lambda x: refind(\"congrat\", x))\n",
    "sms[\"subscri\"] = sms[\"v2\"].apply(lambda x: refind(\"subscri\", x))\n",
    "sms[\"guarantee\"] = sms[\"v2\"].apply(lambda x: refind(\"guarantee\", x))\n",
    "sms[\"account\"] = sms[\"v2\"].apply(lambda x: refind(\"account\", x))\n",
    "sms[\"prize\"] = sms[\"v2\"].apply(lambda x: refind(\"prize\", x))\n",
    "sms[\"bonus\"] = sms[\"v2\"].apply(lambda x: refind(\"bonus\", x))\n",
    "sms[\"award\"] = sms[\"v2\"].apply(lambda x: refind(\"award\", x))\n",
    "sms[\"ansr\"] = sms[\"v2\"].apply(lambda x: refind(\"ansr\", x))\n",
    "sms[\"pobox\"] = sms[\"v2\"].apply(lambda x: refind(\"pobox\", x))\n",
    "sms[\"msg\"] = sms[\"v2\"].apply(lambda x: refind(\"msg\", x))\n",
    "## and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eZlvuLkZ9jZg"
   },
   "outputs": [],
   "source": [
    "def findtokens(string, text):\n",
    "    list_of_tokens = re.findall(r\"[a-z0-9]\", text)\n",
    "    return list_of_tokens.count(string)\n",
    "sms[\"com\"] = sms[\"v2\"].apply(lambda x: findtokens(\"com\", x))\n",
    "sms[\"net\"] = sms[\"v2\"].apply(lambda x: findtokens(\"net\", x))\n",
    "sms[\"www\"] = sms[\"v2\"].apply(lambda x: findtokens(\"www\", x))\n",
    "sms[\"wap\"] = sms[\"v2\"].apply(lambda x: findtokens(\"wap\", x))\n",
    "sms[\"click\"] = sms[\"v2\"].apply(lambda x: findtokens(\"click\", x))\n",
    "sms[\"win\"] = sms[\"v2\"].apply(lambda x: findtokens(\"win\", x))\n",
    "sms[\"won\"] = sms[\"v2\"].apply(lambda x: findtokens(\"won\", x))\n",
    "sms[\"password\"] = sms[\"v2\"].apply(lambda x: findtokens(\"password\", x))\n",
    "sms[\"urgent\"] = sms[\"v2\"].apply(lambda x: findtokens(\"urgent\", x))\n",
    "sms[\"winner\"] = sms[\"v2\"].apply(lambda x: findtokens(\"winner\", x))\n",
    "sms[\"private\"] = sms[\"v2\"].apply(lambda x: findtokens(\"private\", x))\n",
    "sms[\"text\"] = sms[\"v2\"].apply(lambda x: findtokens(\"text\", x))\n",
    "sms[\"call\"] = sms[\"v2\"].apply(lambda x: findtokens(\"call\", x))\n",
    "sms[\"code\"] = sms[\"v2\"].apply(lambda x: findtokens(\"code\", x))\n",
    "sms[\"valid\"] = sms[\"v2\"].apply(lambda x: findtokens(\"valid\", x))\n",
    "sms[\"cash\"] = sms[\"v2\"].apply(lambda x: findtokens(\"cash\", x))\n",
    "sms[\"claim\"] = sms[\"v2\"].apply(lambda x: findtokens(\"claim\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2y5cRKAZ9jZk"
   },
   "outputs": [],
   "source": [
    "## Linear Discriminant Analysis on my own feature extraction\n",
    "x = sms.iloc[:,5:]\n",
    "y = sms[\"v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sZlbt13N9jZm"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.8, random_state = 4236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCELmCVh9jZo",
    "outputId": "c012036c-c42e-4460-f0b6-d9234eab486b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9688200986989681"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlQPwRxE9jZq",
    "outputId": "76cd38b1-1a14-4cdc-baff-3afa421cf5de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515477792732167"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Classifier on my own feature extraction\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
