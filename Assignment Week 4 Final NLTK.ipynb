{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment Week 4: Final NLTK**  \n",
    "**Yigao Li**  \n",
    "*Sep 21, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    file = open(f, encoding = \"utf-8\")\n",
    "    return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " '.',\n",
       " '.',\n",
       " ',',\n",
       " ',',\n",
       " '.',\n",
       " '(',\n",
       " ')',\n",
       " '.',\n",
       " '.',\n",
       " '$',\n",
       " '.',\n",
       " ',',\n",
       " '{',\n",
       " ',',\n",
       " '-',\n",
       " ',',\n",
       " '-',\n",
       " ',',\n",
       " '.',\n",
       " '.',\n",
       " ',',\n",
       " ',',\n",
       " '/',\n",
       " '/',\n",
       " ',',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "text = load(\"corpus.txt\")\n",
    "pattern_a = r'''(?x)\n",
    "[.,\\/#!$%\\^&\\*;:{}=\\-_`~()] # punctuations\n",
    "'''\n",
    "nltk.regexp_tokenize(text, pattern_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computers',\n",
       " '$0.99',\n",
       " 'This',\n",
       " 'Georgetown University',\n",
       " 'Tom',\n",
       " 'Vector',\n",
       " 'This',\n",
       " 'We',\n",
       " 'There',\n",
       " 'We',\n",
       " 'Our',\n",
       " 'Sep 21st, 2018',\n",
       " '9/21/2018']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_b = r'''(?x)\n",
    "\\$\\d+\\.{0,1}\\d+                                           # Monetary\n",
    "|[01]{0,1}\\d\\/[0-3]{0,1}\\d\\/\\d{2,4}                       # Date with /\n",
    "|[01]{0,1}\\d-[0-3]{0,1}\\d-\\d{2,4}                         # Date with -\n",
    "|[A-Z][a-z]{2,8}\\s[0-3]{0,1}\\d[a-z]{0,2},{0,1}\\s\\d{2,4}   # Date in English\n",
    "|\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?                          # Names of people and organizations\n",
    "'''\n",
    "nltk.regexp_tokenize(text, pattern_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Exercise 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "def guess_lang(text):\n",
    "    dutchdict = nltk.FreqDist(nltk.corpus.udhr.words(\"Dutch_Nederlands-Latin1\"))\n",
    "    englishdict = nltk.FreqDist(nltk.corpus.udhr.words(\"English-Latin1\"))\n",
    "    frenchdict = nltk.FreqDist(nltk.corpus.udhr.words(\"French_Francais-Latin1\"))\n",
    "    germandict = nltk.FreqDist(nltk.corpus.udhr.words(\"German_Deutsch-Latin1\"))\n",
    "    spanishdict = nltk.FreqDist(nltk.corpus.udhr.words(\"Spanish-Latin1\"))\n",
    "    if type(text) is nltk.text.Text:\n",
    "        textlist = [w for w in text]\n",
    "    if type(text) == str:\n",
    "        textlist = text.split()\n",
    "    if type(text) == list:\n",
    "        textlist = text\n",
    "    textdict = nltk.FreqDist(textlist)\n",
    "    langdict = {0:\"Dutch\", 1:\"English\", 2:\"French\", 3:\"German\", 4:\"Spanish\"}\n",
    "    score = []\n",
    "    score.append(nltk.spearman_correlation(textdict, dutchdict))\n",
    "    score.append(nltk.spearman_correlation(textdict, englishdict))\n",
    "    score.append(nltk.spearman_correlation(textdict, frenchdict))\n",
    "    score.append(nltk.spearman_correlation(textdict, germandict))\n",
    "    score.append(nltk.spearman_correlation(textdict, spanishdict))\n",
    "    print(score)\n",
    "    return langdict.get(score.index(max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7182522903453137, -1891.5, -1232.5, -72.85, -12999.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dutch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an article in Dutch\n",
    "guess_lang(load(\"language.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-214.49094076655052, -0.08018081194799298, -62.81496960486322, -108.97362949994529, -70.84362226920366]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be English\n",
    "guess_lang(text6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
